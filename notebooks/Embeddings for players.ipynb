{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Processing Pipeline for Soccer Player Embeddings\n",
    "\n",
    "This notebook implements a comprehensive data processing pipeline for creating player embeddings from the European Soccer Database. The pipeline includes data extraction, temporal weighting, and feature normalization to prepare player profiles for machine learning applications.\n",
    "\n",
    "### Key Features:\n",
    "- Temporal weighting to emphasize recent player performance\n",
    "- Comprehensive attribute normalization\n",
    "- Player profile aggregation across multiple time periods\n",
    "- Embedding-ready data preparation"
   ],
   "id": "c8b958ef174b272"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Library Imports\n",
    "Setting up the required libraries for data processing, machine learning, and database operations."
   ],
   "id": "b75b9a65fe131e76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:28:55.442267Z",
     "start_time": "2025-07-06T16:28:55.260794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import _sqlite3 as db\n",
    "import pickle, json"
   ],
   "id": "4fc99e51ad3064d5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Database Connection and Table Exploration\n",
    "Connecting to the European Soccer Database and exploring available tables to understand the data structure."
   ],
   "id": "de0a5e24e3d29249"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:28:57.809114Z",
     "start_time": "2025-07-06T16:28:57.799813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# function for tables extraction\n",
    "def extract_tables(cursor):\n",
    "    for row in cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\"):\n",
    "        print(row)\n",
    "\n",
    "# Extraction tables from European Soccer Database (https://www.kaggle.com/datasets/hugomathien/soccer?resource=download)\n",
    "con_euro = db.connect('Data/EuroSoccer.sqlite')\n",
    "cursor = con_euro.cursor()\n",
    "\n",
    "print(\"Tables from European Soccer Database:\\n\")\n",
    "extract_tables(cursor)\n",
    "print('\\n')"
   ],
   "id": "b9268b1c32a67366",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables from European Soccer Database:\n",
      "\n",
      "('sqlite_sequence',)\n",
      "('Player_Attributes',)\n",
      "('Player',)\n",
      "('Match',)\n",
      "('League',)\n",
      "('Country',)\n",
      "('Team',)\n",
      "('Team_Attributes',)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Data Loading and Integration\n",
    "Loading player information and attributes from the database, then merging them to create a comprehensive dataset with temporal player data."
   ],
   "id": "8faf5e8a6a62a26e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:29:02.732875Z",
     "start_time": "2025-07-06T16:29:00.291124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "players = pd.read_sql_query(\"SELECT * FROM Player\", con_euro)\n",
    "player_attributes = pd.read_sql_query(\"SELECT * FROM Player_Attributes\", con_euro)\n",
    "\n",
    "players_with_attributes = players.merge(\n",
    "    player_attributes,\n",
    "    on='player_api_id',\n",
    "    how='left',\n",
    "    suffixes=('', '_attr')\n",
    ")\n",
    "\n",
    "players_with_attributes = players_with_attributes.sort_values(\n",
    "    ['player_api_id', 'date']\n",
    ").reset_index(drop=True)"
   ],
   "id": "1af465abd6bf05cf",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Data Quality Assessment\n",
    "Exploring the dataset structure, checking for missing values, and understanding the temporal distribution of player records."
   ],
   "id": "e9caee6dabd6baed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:29:05.373325Z",
     "start_time": "2025-07-06T16:29:05.368176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(players_with_attributes.columns.tolist())\n",
    "print(len(players_with_attributes.columns.tolist()))"
   ],
   "id": "8bce4ad07ce08255",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'player_api_id', 'player_name', 'player_fifa_api_id', 'birthday', 'height', 'weight', 'id_attr', 'player_fifa_api_id_attr', 'date', 'overall_rating', 'potential', 'preferred_foot', 'attacking_work_rate', 'defensive_work_rate', 'crossing', 'finishing', 'heading_accuracy', 'short_passing', 'volleys', 'dribbling', 'curve', 'free_kick_accuracy', 'long_passing', 'ball_control', 'acceleration', 'sprint_speed', 'agility', 'reactions', 'balance', 'shot_power', 'jumping', 'stamina', 'strength', 'long_shots', 'aggression', 'interceptions', 'positioning', 'vision', 'penalties', 'marking', 'standing_tackle', 'sliding_tackle', 'gk_diving', 'gk_handling', 'gk_kicking', 'gk_positioning', 'gk_reflexes']\n",
      "48\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:29:07.151022Z",
     "start_time": "2025-07-06T16:29:07.140648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Number of notes: {players_with_attributes.shape}\")\n",
    "print(f\"Number of unique players: {players_with_attributes['player_api_id'].nunique()}\")"
   ],
   "id": "762ed71c2d0e49ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of notes: (183978, 48)\n",
      "Number of unique players: 11060\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Temporal Weighting Implementation\n",
    "Applying exponential decay weighting to player attributes to emphasize more recent performance data. This approach ensures that recent player form is weighted more heavily than historical data."
   ],
   "id": "cbec12e7424c680d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:30:56.286641Z",
     "start_time": "2025-07-06T16:29:09.265146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 'preferred_foot', 'attacking_work_rate', 'defensive_work_rate' - преобразовать в числа если нужны\n",
    "\n",
    "attributes = [\n",
    "    'overall_rating', 'potential', 'crossing', 'finishing', 'heading_accuracy', 'short_passing', 'volleys', 'dribbling', 'curve', 'free_kick_accuracy', 'long_passing', 'ball_control', 'acceleration', 'sprint_speed', 'agility', 'reactions', 'balance', 'shot_power', 'jumping', 'stamina', 'strength', 'long_shots', 'aggression', 'interceptions', 'positioning', 'vision', 'penalties', 'marking', 'standing_tackle', 'sliding_tackle', 'gk_diving', 'gk_handling', 'gk_kicking', 'gk_positioning', 'gk_reflexes'\n",
    "]\n",
    "\n",
    "print(\"Missed values in attributes:\")\n",
    "for attr in attributes:\n",
    "    if attr in players_with_attributes.columns:\n",
    "        missing = players_with_attributes[attr].isnull().sum()\n",
    "        print(f\"{attr}: {missing} ({missing/len(players_with_attributes)*100:.1f}%)\")\n",
    "print(f\"\\nMean of notes by payers: {len(players_with_attributes)/players_with_attributes['player_api_id'].nunique():.1f}\")\n",
    "print(f\"Number of players with one note: {(players_with_attributes['player_api_id'].value_counts() == 1).sum()}\")\n",
    "\n",
    "\n",
    "def apply_temporal_weights_to_players(players_df, decay_factor=0.95):\n",
    "    weighted_players = []\n",
    "    for player_id, group in players_df.groupby('player_api_id'):\n",
    "        if group['date'].isnull().all():\n",
    "            continue\n",
    "        # sort by data from old -> to new\n",
    "        group = group.sort_values('date').reset_index(drop=True)\n",
    "        # calculate of weights\n",
    "        n_records = len(group)\n",
    "        weights = np.array([decay_factor ** (n_records - i - 1) for i in range(n_records)])\n",
    "        # apply weights to attributes\n",
    "        weighted_group = group.copy()\n",
    "        for attr in attributes:\n",
    "            if attr in group.columns and not group[attr].isnull().all():\n",
    "                weighted_group[f'{attr}_weighted'] = group[attr] * weights\n",
    "        weighted_players.append(weighted_group)\n",
    "    return pd.concat(weighted_players, ignore_index=True)\n",
    "\n",
    "# apply weights\n",
    "players_weighted = apply_temporal_weights_to_players(players_with_attributes)\n",
    "print(f\"Data with: {players_weighted.shape}\")"
   ],
   "id": "19ff060cdf23b08a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed values in attributes:\n",
      "overall_rating: 836 (0.5%)\n",
      "potential: 836 (0.5%)\n",
      "crossing: 836 (0.5%)\n",
      "finishing: 836 (0.5%)\n",
      "heading_accuracy: 836 (0.5%)\n",
      "short_passing: 836 (0.5%)\n",
      "volleys: 2713 (1.5%)\n",
      "dribbling: 836 (0.5%)\n",
      "curve: 2713 (1.5%)\n",
      "free_kick_accuracy: 836 (0.5%)\n",
      "long_passing: 836 (0.5%)\n",
      "ball_control: 836 (0.5%)\n",
      "acceleration: 836 (0.5%)\n",
      "sprint_speed: 836 (0.5%)\n",
      "agility: 2713 (1.5%)\n",
      "reactions: 836 (0.5%)\n",
      "balance: 2713 (1.5%)\n",
      "shot_power: 836 (0.5%)\n",
      "jumping: 2713 (1.5%)\n",
      "stamina: 836 (0.5%)\n",
      "strength: 836 (0.5%)\n",
      "long_shots: 836 (0.5%)\n",
      "aggression: 836 (0.5%)\n",
      "interceptions: 836 (0.5%)\n",
      "positioning: 836 (0.5%)\n",
      "vision: 2713 (1.5%)\n",
      "penalties: 836 (0.5%)\n",
      "marking: 836 (0.5%)\n",
      "standing_tackle: 836 (0.5%)\n",
      "sliding_tackle: 2713 (1.5%)\n",
      "gk_diving: 836 (0.5%)\n",
      "gk_handling: 836 (0.5%)\n",
      "gk_kicking: 836 (0.5%)\n",
      "gk_positioning: 836 (0.5%)\n",
      "gk_reflexes: 836 (0.5%)\n",
      "\n",
      "Mean of notes by payers: 16.6\n",
      "Number of players with one note: 0\n",
      "Data with: (183978, 83)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6. Player Profile Generation\n",
    "Creating aggregated player profiles by computing weighted averages of all attributes for each player. This step consolidates multiple temporal records into a single representative profile."
   ],
   "id": "b66599e58aebc0c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:32:41.730664Z",
     "start_time": "2025-07-06T16:31:40.959211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_player_profiles(weighted_players_df):\n",
    "    player_profiles = {}\n",
    "    for player_id, group in weighted_players_df.groupby('player_api_id'):\n",
    "        if group.empty:\n",
    "            continue\n",
    "        profile = {'player_api_id': player_id}\n",
    "        # General data (just for checking)\n",
    "        latest_record = group.iloc[-1]\n",
    "        profile.update({\n",
    "            'player_name': latest_record['player_name'],\n",
    "            'height': latest_record['height'],\n",
    "            'weight': latest_record['weight'],\n",
    "            'preferred_foot': latest_record['preferred_foot'],\n",
    "            'attacking_work_rate': latest_record['attacking_work_rate'],\n",
    "            'defensive_work_rate': latest_record['defensive_work_rate']\n",
    "        })\n",
    "        # weighed number attributes\n",
    "        weights = np.array([0.95 ** (len(group) - i - 1) for i in range(len(group))])\n",
    "        for attr in attributes:\n",
    "            if attr in group.columns and not group[attr].isnull().all():\n",
    "                valid_data = group[attr].dropna()\n",
    "                if len(valid_data) > 0:\n",
    "                    # take according data\n",
    "                    valid_weights = weights[-len(valid_data):]\n",
    "                    profile[attr] = np.average(valid_data, weights=valid_weights)\n",
    "        player_profiles[player_id] = profile\n",
    "    return player_profiles\n",
    "\n",
    "player_profiles = create_player_profiles(players_weighted)\n",
    "print(f\"Number of profiles: {len(player_profiles)}\")\n"
   ],
   "id": "675138292d189f4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of profiles: 11060\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7. Embedding Data Preparation\n",
    "Preparing the final dataset for embedding generation by:\n",
    "- Normalizing all numerical features using StandardScaler\n",
    "- Creating player ID mappings for efficient indexing\n",
    "- Saving the processed data for downstream applications"
   ],
   "id": "e268138cb4a388f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:33:03.186105Z",
     "start_time": "2025-07-06T16:33:02.790877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_embeddings_data(player_profiles):\n",
    "    profiles_df = pd.DataFrame(list(player_profiles.values()))\n",
    "\n",
    "    # mapping: player_api_id -> sequential_id\n",
    "    unique_players = list(player_profiles.keys())\n",
    "    player_id_to_idx = {pid: idx for idx, pid in enumerate(unique_players)}\n",
    "    idx_to_player_id = {idx: pid for pid, idx in player_id_to_idx.items()}\n",
    "\n",
    "    # normalization of data\n",
    "    numeric_features = [attr for attr in attributes if attr in profiles_df.columns]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    profiles_df[numeric_features] = scaler.fit_transform(\n",
    "        profiles_df[numeric_features].fillna(profiles_df[numeric_features].mean())\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'profiles_df': profiles_df,\n",
    "        'player_id_to_idx': player_id_to_idx,\n",
    "        'idx_to_player_id': idx_to_player_id,\n",
    "        'scaler': scaler,\n",
    "        'numeric_features': numeric_features\n",
    "    }\n",
    "\n",
    "embeddings_data = prepare_embeddings_data(player_profiles)\n",
    "scaler = prepare_embeddings_data(player_profiles)['scaler']\n",
    "print(f\"Prepared for embedding: {len(embeddings_data['player_id_to_idx'])} players\")\n",
    "\n",
    "with open('embeddings_data.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_data, f)\n",
    "\n",
    "print(\"embeddings saved as embeddings_data.pkl\")"
   ],
   "id": "9dfd1ad113bd5151",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared for embedding: 11060 players\n",
      "embeddings saved as embeddings_data.pkl\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
